
Гетерогенная параллелизация — это подход, когда вычисления распределяются между разными типами вычислительных устройств (обычно CPU + GPU), чтобы каждое устройство выполняло ту часть работы, для которой оно наиболее эффективно.
1) Различия параллельных вычислений на CPU и GPU
CPU (центральный процессор):
мало ядер (обычно 4–16), но они “сильные”
хорошо подходит для ветвлений, сложной логики, последовательных участков
низкие задержки (latency), сильная кэш-система
GPU (графический/вычислительный процессор):
очень много “простых” ядер (сотни/тысячи потоков)
идеально для массово-параллельных задач: одинаковая операция над большим числом элементов
высокая пропускная способность (throughput), но хуже с ветвлениями и нерегулярным доступом к памяти
2) Преимущества гетерогенной параллелизации
Ускорение: CPU делает управление/логические части, GPU — тяжёлые параллельные вычисления.
Эффективность ресурсов: не простаивает ни CPU, ни GPU.
Лучшее время/стоимость: можно добиться высокой производительности без сверхдорогих CPU.
3) Примеры реальных приложений
Deep Learning (обучение/инференс нейросетей): матричные операции на GPU.
Обработка изображений/видео: фильтры, детекция объектов, кодирование.
Научные расчёты: CFD (гидродинамика), молекулярная динамика, N-body.
Финансы: Монте-Карло симуляции, оценка рисков (VaR/ES) на больших выборках.
