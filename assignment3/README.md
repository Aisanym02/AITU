# Описание
Данная работа посвящена изучению архитектуры GPU и основ оптимизации программ на CUDA.
В рамках задания реализованы несколько CUDA-ядер, демонстрирующих влияние типа памяти, способа доступа к данным и параметров запуска на производительность вычислений.
Все эксперименты выполняются на массивах большого размера с измерением времени выполнения на GPU.
# Цель работы
Целью данной работы является:
изучение принципов работы глобальной и разделяемой памяти GPU;
анализ влияния размера блока потоков на производительность;
исследование коалесцированного и некоалесцированного доступа к памяти;
подбор оптимальных параметров запуска CUDA-ядер.
# Структура задания
## Задание 1 — Поэлементная обработка массива
Реализовано умножение элементов массива на константу двумя способами:
с использованием только глобальной памяти;
с использованием разделяемой (shared) памяти.
Проводится сравнение времени выполнения обоих вариантов.
Показано, что для простых операций использование shared memory не всегда даёт ускорение.
## Задание 2 — Сложение массивов и влияние размера блока
Реализовано поэлементное сложение двух массивов на GPU.
Выполнены запуски ядра с разными размерами блока потоков:
128
256
512
Измеряется и сравнивается время выполнения для каждого варианта.
## Задание 3 — Коалесцированный и некоалесцированный доступ к памяти
Реализованы два CUDA-ядра:
с коалесцированным доступом к глобальной памяти;
с некоалесцированным доступом (через stride).
Проводится сравнение производительности, демонстрирующее существенное замедление при неэффективном доступе к памяти.
Задание 4 — Оптимизация параметров запуска
На примере сложения массивов сравниваются:
неоптимальная конфигурация запуска (малый размер блока);
более оптимальная конфигурация (типичный размер блока 256).
Рассчитывается относительное ускорение при использовании оптимальных параметров.
Используемые технологии
Язык программирования: C++
Параллельные вычисления: CUDA
Модель памяти GPU: global / shared
Измерение времени: cudaEvent

# Результаты и выводы
Использование shared memory не всегда ускоряет простые операции.
Производительность CUDA-ядер существенно зависит от размера блока потоков.
Коалесцированный доступ к памяти значительно быстрее некоалесцированного.
Правильный подбор параметров запуска позволяет получить заметное ускорение.
Работа демонстрирует основные принципы оптимизации CUDA-программ и особенности архитектуры GPU.
